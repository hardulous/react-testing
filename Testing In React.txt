####### TESTING #######

As a developer our primary goal is to build software (like website, social media app etc) that works, If it does not then it does not matter how much effort we put in ui/ux and performance. To ensure our software works, we test the application and check if our software work as expected, For this we rely on 2 type of testing ::

1. MANUAL TESTING => An individual like tester and quality assurance (qa) team will interact with the software and ensure everything works as intended. If a new feature is released the same steps repeat, However depending on what a feature is we may have to test not only the new feautre but also the existing feautres to ensure app as a whole continue to work. Drawbacks :: 

(a). Time consuming as depending on a feature and how large an application is the tester will test the whole application again. 

(b). Complex repeatitive task has a risk of human error. 

(c). Given the tight deadline we may not get a chance to test all the features we should. 

(d). Sometime leads to shipping software that contain some errors and does not work as intended

Now the solution to above drawbacks is "AUTOMATED TESTING"

2. AUTOMATED TESTING => These are programs that automate the task of testing the software. Basically a code to test the software code. Offcourse additional effort like writing test code are required when we develop a feature but this initial investment will pay-off in a long run. Advantage ::

(a). Not time consuming as the tester is not doing any manual testing as everything is automated by test code. 

(b). Reliable, consistent and not error prone as computer is good at doing complex repeatitive task. 

(c). Easy to identify and fix feature that breaks tests when changes are made to the software code. As a developer we can verify other developer work and ensure that does not break the software.

(d). Gives confidence when shipping software that works as intended


###### JEST VS RTL (REACT TESTING LIBRARY) #######

Jest is a javascript testing framework, It is a test runner that finds tests, runs the tests, determines whether the tests passed or failed and reports it back in a human readable manner. 

RTL is a javascript testing utility that provides virtual DOM for testing REACT components, Though the automated test we will be writing there is not actual DOM to work with. RTL provides a virtual DOM which we can use to interact with and verify the behaviour of a react component. 

Here the testing LIBRARY is infact a family of packages which helps test UI components. The core library is called DOM testing library and RTL is simply a wrapper around this core library to test React applications in an easier way. 

FOR TESTING WE WILL BE USING BOTH THE LIBRARY TOGETHER 


@@@@@ NOTE @@@@@

Enzyme (Deprecated)
Enzyme was a React testing utility created by Airbnb that provided more control over component rendering. It allowed shallow, mount, and static rendering to test React components in isolation. However, it is now deprecated and does not support React 18+. React Testing Library is now the preferred choice.

Avoid Enzyme, as it is outdated and does not support newer React versions.


###### TYPES OF TESTS #######

There are many types of test but mostly we come across 3 types ::

1. UNIT TEST => Focus on testing the individual building blocks of an application such as a class or a function component. Each unit or building block is tested in isolation independent of other units. Dependencies are mocked, Run in a short amount of time and make it very easy to pinpoint failures. Easier to write and maintain. 

2. INTEGRATION TEST => Focus on testing a combination of units and ensures they work together. Take longer than unit tests.

3. E2E TEST => Focus on testing the entire application flow from the user’s perspective from start to finish. Mimics real user interactions. Involves in a real UI, real backend database, real services etc. Take the longest time as it cover the most amount of code. Have a cost implication as we interact with real APIs that may charge based on the number of requests. 


####### TESTING PYRAMID ########

It is a guideline to follow when deciding what type of test we should write for our software. The bulk of the test are unit tests at the bottom of the pyramid, As we go up the pyramid the test gets larger but the number of test get smaller, Then the fewest are e2e test which gives the most confident as it closely resemble a user testing the application. Unit tests are fastest and cheapest, while E2E tests are slow and expensive.


######## RTL PHILOSOPHY ########

The more our tests resemble the way our software is used, the more confidence they can give us. Tests we are going to write should strike a balance between unit tests in the sense they are at a component level and easy to write and maintain and E2E tests in the sense they resemble the way a user would interact with the component. 

With RTL we are not concerned about the implementation details of a component. We only care about how the component behaves when a user interacts with it. FOR EX:: 

RTL will not care if we add 4+4 or 5+3 to display the number 8, As long as the final result is 8 it has np. Any refactoring on our software code will not affect our test as long as the end result is same. 


###### TEST #######

It is a piece of code to test the software code. The piece of code basically just throws an error when actual output does not match the expected output. EX :: let say we have index.js file 

const getFullName= (fname, lname)=>{
    return `${fname} ${lname}`
}

const actualName = getFullName("bruce", "wayne)
const expectedName = "bruce wayne"

if(actualName !== expectedName){
    throw new Error(actualName is not equal to expectedName)
}

Here if we run the above code we will not get any error but if expectedName= "aman bisht", Then we will get an error as actual output is not same as expected which is "bruce wayne" != "aman bisht". Here this ::

if(actualName !== expectedName){
    throw new Error(actualName is not equal to expectedName)
}

above code is my "TEST" code that will pass when output is correct and provide meaningful feedback when it is not. 


####### PACKAGES ######

Here we create our react app using create-react-app the jest and RTL is automatically added as a dependency in it, The packages are "@testing-library/dom", "@testing-library/jest-dom", "@testing-library/react", "@testing-library/user-event" and "jest" which is present in package.json of react-script 


###### RUNNING FIRST TEST ########

The create-react-app comes with a default "App.test" file which contain a test to run. The test check whether an element that contains the text "learn react" (case insensitive due to /i) exists in the document or not.

To run this test in package.json we have script "test": "react-scripts test", This will internally run jest in watch mode and execute all the test in our application and provide result of it whether passed or not in terminal with message. 


####### TEST DRIVEN DEVELOPMENT (TDD) ########

TDD is a software development process where we write tests before writing the software code. Once the tests have been written, We then write the code to ensure the tests pass. This envolves 3 steps ::

1. Create tests that verify the functionality of a specific feature

2. Write software code that will run the tests successfully when re-executed

3. Refactor the code for optimization while ensuring the tests continue to pass (Optional)

Also called red-green testing as all tests go from a red failed state to a green passed state.

TO UNDERSTAND MORE WATCH "https://www.youtube.com/watch?v=foiMMI-pEes&list=PLC3y8-rFHvwirqe1KHFCHJ0RqNuN61SJd&index=9"

####### WATCH MODE ########

We we run command "npm run test" behind the scene it runs jest in watch mode. Watch mode is an option that we can pass to jest asking to watch files that have changed since the last commit and execute tests related only to those changed files. It is an optimization designed to make your tests run fast regardless of how many tests we have. 

Let say we have 2 test greet.test and app.test now initially both test case will run when we do "npm run test", After that if we make changes to only greet component which is getting test in greet.test then only that test file will run again and app.test will not. 


######## FILTERING TESTS #########

Here when we run "npm run test" under the watch usage we have multiple filtering option allow us to to run test case in different way like, run all tests, run only failed tests, filter test by a fileName regex, filter test by a test name regex. They come handy when we want to filter test case in a large codebase.

Apart from filtering there are global method available from jest like test.only() and test.skip().

1. only() => If you want to run only one test (or a few tests) out of many test in a .test file while debugging, use test.only().
Only the test with test.only() will run, and all other tests in the file will be ignored.

2. skip() => If you want to temporarily disable a test, use test.skip(). Jest marks skipped tests in the output but doesn't run them.

TO UNDERSTAND MODE WATCH "https://www.youtube.com/watch?v=2TkpBziqkRA&list=PLC3y8-rFHvwirqe1KHFCHJ0RqNuN61SJd&index=11"


######### GROUPING TESTS ###########

Jest provide us way to organize related tests in group which helps organize tests logically, making them easier to read and maintain. For this jest provide us global method called "describe()". 

describe(name, fn) ::

1. name => Group name.

2. fn => Function that contains the expectations to test.

Here in fn function we put our test case "test(name, fn)" in which actual test defination is present. The describe() also provide .skip() and .only()

If you want to run only one specific test group and ignore all others, use describe.only().

If you want to temporarily disable a group of tests, use describe.skip().

In a single test file we can have multiple describe() block just like multiple test() block. We can have nested describe() block as well.

In terminal window of a test::

A test suites corresponds to a file which contains test like "Greet.test" and "App.test" getting executed by jest in watch mode. Even if we group test together using describe() it does not corresponds to a test suites. 


######### FILENAME CONVENTIONS ##########

Here till now we have created our test using filename ".test.tsx" file but in jest with CRA provide multiple filename conventions to create a test file. ::

1. Files with .test.js, .test.jsx, .test.ts and .test.tsx suffix
2. Files with .spec.js, .spec.jsx, .spec.ts and .spec.tsx suffix
3. Files with .js, .jsx, .ts and .tsx suffix in __tests__ folders

Recommendation is to always put your tests next to the code they are testing so that relative imports are shorter. 

Here just like .test(), .only() and .skip() we have it(), fit() and xit() are global functions provided by jest.

1. it() => It is used to define test case similar to .test(). 

2. fit() => fit stands for "focused it" and is used to run only that specific test, ignoring others similar to ".only()".

3. xit() => xit stands for "excluded it" and skips the test similar to ".skip()".


###### CODE COVERAGE ########

It is a metric that can help us understand how much of our software code is tested. It provide us metric like ::

1. Statement coverage => % Stmts – Percentage of statements (lines) covered, How many of the statements in the software code have been executed. 

2. Branch coverage => % Branch – Percentage of conditionals (if/else, switch) covered, How many of the branches of the control structures have been executed. 

3. Function coverage => % Funcs – Percentage of functions covered, How many of the functions defined in the software code have been tested.

4. Line coverage => % Lines – Percentage of actual lines covered, How many of lines of source code have been tested

5. Uncovered Line => Uncovered Line #s – The line numbers missing tests, The Line numbers that were not executed by any test. EX :: If there's an if condition that never gets tested, its lines remain uncovered. If a function is defined but never used in tests, Jest won’t execute it. If you don’t write tests for error cases (e.g., catch blocks), those lines remain uncovered.

Here CRA with jest provide support to request "code coverage report" in HTML format. For this we add new script in package.json " coverage: 'react-scripts test --coverage' ".  

Here running above command will show a table of above metrices as a part of output. The table will be empty if the all test case has already run before and no new commit are present in code, So to watch for all files and not only for changed files we add another flag in script "--watchAll".

Our goal using this table is to turn the red % into green % by writing test case for that file. Here most of the time we don not write test case for "index.tsx" and "reportWebVitals.ts", So we can make jest ignore those files using flag "--collectCoverageFrom". So "--collectCoverageFrom='src/Components/**/*.{ts,tsx}" , It means inside src/Components directory collects coe coverage only from .ts and .tsx files at any subDirectory level **/.

Here in large code base we will have some files that does not need a test case. Let say in Greet folder we have a type defination file Greet.types.ts and we don't want test case for this so we can make jest ignore this file using "--collectCoverageFrom" with "!" sign, --collectCoverageFrom='!src/Components/**/*.types.{ts,tsx}. It means excludes all typeScript type definition files (.types.ts and .types.tsx) from Jest coverage.

Jest also allows us to set coverage thresholds, ensuring that your tests cover a minimum percentage of statements, branches, functions, and lines. If coverage falls below the set threshold, Jest will fail the test run. For this add in package.json ::  

 "jest":{
   "coverageThreshold":{
     "global":{
        "branches":80
        "functions":80
        "lines":80
        "statements":-10
     }
   } 
  }

Here above config state jest will fail if there is less that 80% coverage in all metrics and if more than 10 uncovered statements. 

To understand uncovered statement add a branch (if/else) logic in Greet.tsx

Using coverage jest also create a coverage report under coverage directory in "index.html" which is in ui friendly manner. It is not necessary to always reach 100% coverage as 80% coverage is also good. 


####### ASSERTIONS ########

Assertions in Jest help validate expected outputs in test cases. They check if a function returns the expected value or if certain conditions hold true. EX ::

In Greet component test case we are asserting if the word "Hello" exists in virtual DOM. 

Assertions decide if a test passes or fails. Parts of assertions ::

1. expect(value) => In jest assertions are carried out using global expect() which takes argument value that your code produces. In our ex it is a DOM node that contain "Hello" word, Most of the time we will use expect along with a "matcher" function to assert something about a value. A matcher can optionally accept an argument which is the correct expected value. In our ex the matcher is "toBeInTheDocument()" that verify whether DOM node exists in DOM or not. 

As a beginner we should know about those matcher functions to be used with expect(), For this go to jest docs "https://jestjs.io/docs/using-matchers"

Here jest provide matcher functions for js testing only that does not inlcide ui and DOM so in above docs we will not see "toBeInTheDocument()" matcher, For this we use additional package called "jest-dom" which contain matcher to assert against UI element and DOM. "https://github.com/testing-library/jest-dom" 

Here CRA automaitcally installed all these packages for us and config them as well. In "setupTests.ts" we will see the "jest-dom" package is imported in it, The purpose of this file is to be executed and configure the testing environment before any tests run by jest. 


######### WHAT TO TEST ###########

In an react application we should test following things ::

1. Test if component renders without any error 

2. Test if component renders correctly when passed a set of props without any error 

3. Test if component renders correctly in different states, EX :: if we have a navbar the logged in button should be visible if user is logged out and not visible if user is logged in.  

4. Test if components reacts to events, This is applicable to components like button and form controls which allow user interaction. 

These above are the basic test case we should do and there are more advance test case also. 

What not to test ::

1. Implementation details, The test case should be around how the software will be used and not how software is implemented 

2. Third party code, We should test the code we have written and not the code we are consuming from external package, EX :: If we are using mui we should not test their component as they are already well tested but test the component that are using the mui components. 

3. Code that is not important from a user point of view, EX :: We have written a utility function that display date in user friendly format, We don't have to test whether component is calling that function but test if that function returns the date in expected format or not. 